{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_data.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/2022/04/01/books/review/letters-to-the-editor...</td>\n",
       "      <td>To the Editor:Regarding Daphne Merkin’s review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/2022/03/22/technology/bitcoin-miners-environm...</td>\n",
       "      <td>Along a dirt-covered road deep in Texas farm c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/2022/03/19/opinion/abortion-laws-bans-missour...</td>\n",
       "      <td>With Roe v. Wade on thin ice, state legislatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/2022/03/25/sports/baseball/mlb-drug-testing.html</td>\n",
       "      <td>PHOENIX — When the 99-day work stoppage in Maj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/2022/03/15/business/russia-debt-bonds-default...</td>\n",
       "      <td>Russia is teetering on the edge of a possible...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  /2022/04/01/books/review/letters-to-the-editor...   \n",
       "1  /2022/03/22/technology/bitcoin-miners-environm...   \n",
       "2  /2022/03/19/opinion/abortion-laws-bans-missour...   \n",
       "3  /2022/03/25/sports/baseball/mlb-drug-testing.html   \n",
       "4  /2022/03/15/business/russia-debt-bonds-default...   \n",
       "\n",
       "                                            articles  \n",
       "0  To the Editor:Regarding Daphne Merkin’s review...  \n",
       "1  Along a dirt-covered road deep in Texas farm c...  \n",
       "2  With Roe v. Wade on thin ice, state legislatur...  \n",
       "3  PHOENIX — When the 99-day work stoppage in Maj...  \n",
       "4   Russia is teetering on the edge of a possible...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_removal(text):\n",
    "    punctuationfree= \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.articles = df_copy.articles.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "df_copy.articles = df_copy.articles.map(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.articles = df_copy.articles.apply(lambda x: punctuation_removal(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words={'english'},max_df=.70,min_df=2,token_pattern=r'(?u)\\b[A-Za-z]+\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function that tokenizes the \n",
    "def tokenize_text(articles):\n",
    "    output = articles.split(' ')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['tokenized'] = df_copy['articles'].apply(lambda x: tokenize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lmoran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def lemma(text):\n",
    "    output = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return output\n",
    "\n",
    "df_copy['lemmatized'] = df_copy['tokenized'].apply(lambda x: lemma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [to, the, editor, regarding, daphne, merkin’s,...\n",
       "1       [along, a, dirt, covered, road, deep, in, texa...\n",
       "2       [with, roe, v, , wade, on, thin, ice, , state,...\n",
       "3       [phoenix, —, when, the, 99, day, work, stoppag...\n",
       "4       [, russia, is, teetering, on, the, edge, of, a...\n",
       "                              ...                        \n",
       "1023    [johnny, grier, , who, became, the, first, bla...\n",
       "1024    [sometimes, lately, , when, he, hasn’t, been, ...\n",
       "1025    [tijuana, , mexico, —, the, frontier, shape, t...\n",
       "1026    [until, recent, event, at, the, oscar, , the, ...\n",
       "1027    [lisette, coly, and, anastasia, damalas, are, ...\n",
       "Name: lemmatized, Length: 1028, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_strings(text):\n",
    "    empty = ''\n",
    "    for i in text:\n",
    "        empty = empty + ' '+ i\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['back_to_strings'] = df_copy['lemmatized'].apply(lambda x: creating_strings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['back_to_strings'] = df_copy['back_to_strings'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        to the editor regarding daphne merkin’s revie...\n",
       "1        along a dirt covered road deep in texas farm ...\n",
       "2        with roe v  wade on thin ice  state legislatu...\n",
       "3        phoenix — when the 99 day work stoppage in ma...\n",
       "4         russia is teetering on the edge of a possibl...\n",
       "                              ...                        \n",
       "1023     johnny grier  who became the first black refe...\n",
       "1024     sometimes lately  when he hasn’t been rehears...\n",
       "1025     tijuana  mexico — the frontier shape this met...\n",
       "1026     until recent event at the oscar  the film sea...\n",
       "1027     lisette coly and anastasia damalas are at a c...\n",
       "Name: back_to_strings, Length: 1028, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['back_to_strings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df_copy.back_to_strings)\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_10 = NMF(n_components=10)\n",
    "doc_topic = nmf_10.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function from Metis\n",
    "def get_top_terms(topic, n_terms, nmf=nmf_10, terms=terms):\n",
    "    # get the topic components (i.e., term weights)\n",
    "    components = nmf.components_[topic, :]\n",
    "\n",
    "    # get term indices, sorted (descending) by topic weights\n",
    "    top_term_indices = components.argsort()[-n_terms:]\n",
    "    \n",
    "    # use the `terms` array to get the actual top terms\n",
    "    top_terms = np.array(terms)[top_term_indices]\n",
    "    \n",
    "    return top_terms.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['political-white-election-biden-former-house-president-him-trump-mr',\n",
       " 'u-where-me-my-mother-told-charo-woman-her-she',\n",
       " 're-just-people-do-me-your-can-what-my-you',\n",
       " 'c-player-season-n-no-first-tournament-team-point-game',\n",
       " 'u-united-military-country-ukrainian-putin-war-ukraine-russian-russia',\n",
       " 'map-election-bill-democrat-right-republican-law-court-abortion-state',\n",
       " 'senator-school-case-justice-law-black-republican-court-jackson-judge',\n",
       " 'group-first-because-family-work-she-company-her-people-m',\n",
       " 'inflation-market-oil-rate-energy-will-percent-gas-price-company',\n",
       " 'pandemic-school-york-many-vaccine-covid-health-people-dr-city']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = ['-'.join(get_top_terms(i,10)) for i in range(10)]\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['political',\n",
       " 'white',\n",
       " 'election',\n",
       " 'biden',\n",
       " 'former',\n",
       " 'house',\n",
       " 'president',\n",
       " 'him',\n",
       " 'trump',\n",
       " 'mr']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_terms(0, 10, nmf_10, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(stop_words={'english'},max_df=.8,min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df_copy.back_to_strings)\n",
    "terms2 = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_10_2= NMF(n_components=5)\n",
    "doc_topic = nmf_10_2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['them', 'could', 'dr', 'many', 'will', 'city', 'what', 'can', 'people', 'you']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_terms(0,10,nmf_10_2,terms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['political-white-election-biden-former-house-president-him-trump-mr',\n",
       " 'u-where-me-my-mother-told-charo-woman-her-she',\n",
       " 're-just-people-do-me-your-can-what-my-you',\n",
       " 'c-player-season-n-no-first-tournament-team-point-game',\n",
       " 'u-united-military-country-ukrainian-putin-war-ukraine-russian-russia',\n",
       " 'map-election-bill-democrat-right-republican-law-court-abortion-state',\n",
       " 'senator-school-case-justice-law-black-republican-court-jackson-judge',\n",
       " 'group-first-because-family-work-she-company-her-people-m',\n",
       " 'inflation-market-oil-rate-energy-will-percent-gas-price-company',\n",
       " 'pandemic-school-york-many-vaccine-covid-health-people-dr-city']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = ['-'.join(get_top_terms(i,10)) for i in range(10)]\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through initial results, the most important hyperparameter going forward will be the max_df. When we had it set at .9 we received too many generic words in our topics. So we lowered it to .8. We will try lowering it even further with future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics that we see with 10 topics are \n",
    "1. Pandemic and New York City\n",
    "2. Unclear, ends with feminine pronouns\n",
    "3. US politics\n",
    "4. Unclear, ends with masculine pronouns\n",
    "5. Sports\n",
    "6. Ukraine-Russia Conflict\n",
    "7. Pronouns, could be editirials?\n",
    "8. ketanji brown jackson supreme court\n",
    "9. Covid and vaccines\n",
    "10. Gas prices rising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022/04/01'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.url[0][1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['year'] = df_copy.url.apply(lambda x : x[1:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop(df_copy[df_copy['year'] == 'live/2022/'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>articles</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>back_to_strings</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [url, articles, tokenized, lemmatized, back_to_strings, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['url'] == 'interactiv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022/03/25    44\n",
       "2022/03/11    44\n",
       "2022/03/23    44\n",
       "2022/03/31    41\n",
       "2022/03/30    39\n",
       "2022/04/01    39\n",
       "2022/03/09    37\n",
       "2022/03/24    37\n",
       "2022/03/22    37\n",
       "2022/03/08    35\n",
       "2022/03/18    35\n",
       "2022/03/16    34\n",
       "2022/04/06    34\n",
       "2022/04/04    34\n",
       "2022/03/28    32\n",
       "2022/03/14    32\n",
       "2022/03/17    31\n",
       "2022/03/10    30\n",
       "2022/03/29    30\n",
       "2022/03/21    29\n",
       "2022/03/15    29\n",
       "2022/04/05    27\n",
       "2022/03/07    27\n",
       "2022/04/03    26\n",
       "2022/03/13    25\n",
       "2022/03/27    24\n",
       "2022/04/07    21\n",
       "2022/03/20    21\n",
       "2022/03/19    18\n",
       "2022/04/02    17\n",
       "2022/03/12    16\n",
       "2022/03/26    16\n",
       "2022/03/04     6\n",
       "2022/03/05     4\n",
       "2022/04/08     2\n",
       "2022/03/03     2\n",
       "2022/03/06     2\n",
       "2022/02/22     1\n",
       "2022/02/24     1\n",
       "2022/01/31     1\n",
       "2022/02/10     1\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>articles</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>back_to_strings</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>/article/federal-reserve-rate-increase.html</td>\n",
       "      <td>consumers are already feeling squeezed by high...</td>\n",
       "      <td>[consumers, are, already, feeling, squeezed, b...</td>\n",
       "      <td>[consumer, are, already, feeling, squeezed, by...</td>\n",
       "      <td>consumer are already feeling squeezed by high...</td>\n",
       "      <td>article/fe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             url  \\\n",
       "347  /article/federal-reserve-rate-increase.html   \n",
       "\n",
       "                                              articles  \\\n",
       "347  consumers are already feeling squeezed by high...   \n",
       "\n",
       "                                             tokenized  \\\n",
       "347  [consumers, are, already, feeling, squeezed, b...   \n",
       "\n",
       "                                            lemmatized  \\\n",
       "347  [consumer, are, already, feeling, squeezed, by...   \n",
       "\n",
       "                                       back_to_strings        year  \n",
       "347   consumer are already feeling squeezed by high...  article/fe  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy.year.str.startswith('article',1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['year'] = pd.to_datetime(df_copy[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bertopic[visualization]print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_csv('converted_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mercy\n"
     ]
    }
   ],
   "source": [
    "print('mercy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mercy\n"
     ]
    }
   ],
   "source": [
    "print('mercy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-73439590a8bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_copy' is not defined"
     ]
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
